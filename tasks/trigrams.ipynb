{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Trigram Language Model Analysis and Generation**\n",
    "\n",
    "This notebook shows the construction of a trigram-based language model. We use a corpus from Project Gutenberg, process the text to calculate trigram frequencies, and generate new text based on trigram probabilities. The tasks include text sanitization, trigram frequency analysis, probability calculation, text generation, and model evaluation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 1: Third-Order Trigram Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Sanitization\n",
    "Sanitize text by removing unwanted characters and converting it to uppercase. The `sanitize_text()` function performs this, retaining only uppercase letters, spaces, and periods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def sanitize_text(text):\n",
    "    # Define start and end markers for Project Gutenberg text\n",
    "    start_marker = \"*** START OF THE PROJECT GUTENBERG EBOOK\"\n",
    "    end_marker = \"*** END OF THE PROJECT GUTENBERG EBOOK\"\n",
    "\n",
    "    # Find where the actual book content starts and ends\n",
    "    start_index = text.find(start_marker)\n",
    "    end_index = text.find(end_marker)\n",
    "\n",
    "    # Extract the main text content between the start and end markers\n",
    "    if start_index != -1:\n",
    "        text = text[start_index + len(start_marker):]\n",
    "    if end_index != -1:\n",
    "        text = text[:end_index]\n",
    "\n",
    "    # Remove newlines and carriage returns ?\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ').replace('\\u200a', '')\n",
    "\n",
    "    # Remove special characters (retain letters, numbers, and spaces)\n",
    "    sanitized_text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
    "\n",
    "    # Convert all text to uppercase\n",
    "    sanitized_text = sanitized_text.upper()\n",
    "\n",
    "    # Strip leading and trailing whitespace\n",
    "    sanitized_text = sanitized_text.strip()\n",
    "\n",
    "    return sanitized_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def read_and_sanitize_file(file_path):\n",
    "    \"\"\"Read the content of the file, sanitize and trim it.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    sanitized_text = sanitize_text(text)\n",
    "    return sanitized_text\n",
    "\n",
    "def read_files_in_folder(folder_path):\n",
    "    \"\"\"Read and sanitize every file in the specified folder.\"\"\"\n",
    "    sanitized_files_content = {}\n",
    "\n",
    "    # Iterate through each file in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Check if the current path is a file\n",
    "        if os.path.isfile(file_path):\n",
    "            print(f\"Reading file: {file_name}\")  # Output the name of each file\n",
    "            sanitized_content = read_and_sanitize_file(file_path)\n",
    "            sanitized_files_content[file_name] = sanitized_content\n",
    "\n",
    "    return sanitized_files_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigram Model Construction\n",
    "The `update_trigram_model()` function creates a trigram frequency model, counting occurrences of three-character sequences across the text.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def update_trigram_model(trigram_model, text):\n",
    "    \"\"\"Update the trigram model with counts from the given text.\"\"\"\n",
    "    for i in range(len(text) - 2):\n",
    "        trigram = text[i:i+3]\n",
    "        trigram_model[trigram] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def build_trigram_model_from_directory(directory):\n",
    "    # Initialize an empty trigram model as a defaultdict\n",
    "    trigram_model = defaultdict(int)\n",
    "\n",
    "    # Read sanitized text from all files in the directory\n",
    "    sanitized_files_content = read_files_in_folder(directory)\n",
    "\n",
    "    print(\"Build a trigram model from all the text files in the specified directory...\\n\")\n",
    "    # Update the trigram model with each file's content\n",
    "    for content in sanitized_files_content.values():\n",
    "        update_trigram_model(trigram_model, content)\n",
    "\n",
    "    # Return the final trigram model\n",
    "    return trigram_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: Trigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: Alice_In_Wonderland.txt\n",
      "Reading file: Frankenstein.txt\n",
      "Reading file: Great_Gatsby.txt\n",
      "Reading file: Moby_Dick.txt\n",
      "Reading file: Pride_And_Prejudice.txt\n",
      "Build a trigram model from all the text files in the specified directory...\n",
      "\n",
      "Trigram: ALI, Count: 1023\n",
      "Trigram: LIC, Count: 784\n",
      "Trigram: ICE, Count: 1441\n",
      "Trigram: CES, Count: 899\n",
      "Trigram: ES , Count: 8058\n",
      "Trigram: S A, Count: 7457\n",
      "Trigram:  AD, Count: 884\n",
      "Trigram: ADV, Count: 283\n",
      "Trigram: DVE, Count: 57\n",
      "Trigram: VEN, Count: 1500\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "folder_path = os.path.join(os.getcwd(), 'project_gutenberg')\n",
    "trigram_model = build_trigram_model_from_directory(folder_path)\n",
    "\n",
    "# Printing some trigrams to see the output\n",
    "for trigram, count in list(trigram_model.items())[:10]:\n",
    "    print(f\"Trigram: {trigram}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Third-order letter approximation generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Counts to Probabilities\n",
    "The `compute_trigram_probabilities()` function calculates probabilities for each trigram, enabling text generation based on character sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\"\"\"Convert trigram counts to probabilities of next characters.\"\"\"\n",
    "def compute_trigram_probabilities(trigram_model):\n",
    "    # Dictionary to store probabilities\n",
    "    trigram_probabilities = defaultdict(dict)\n",
    "    \n",
    "    # Group trigrams by their first two characters (the prefix)\n",
    "    prefix_counts = defaultdict(int)\n",
    "    \n",
    "    # Calculate the total counts for each prefix (first two characters)\n",
    "    for trigram, count in trigram_model.items():\n",
    "        prefix = trigram[:2]\n",
    "        prefix_counts[prefix] += count\n",
    "    \n",
    "    # Convert counts to probabilities\n",
    "    for trigram, count in trigram_model.items():\n",
    "        prefix = trigram[:2]\n",
    "        probability = count / prefix_counts[prefix]\n",
    "        trigram_probabilities[prefix][trigram[2]] = probability  # Map next character to its probability\n",
    "    \n",
    "    return trigram_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation\n",
    "The `generate_text()` function uses trigram probabilities to iteratively generate text, starting from a specified two-character sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\"\"\"Given a prefix, sample the next character based on trigram probabilities.\"\"\"\n",
    "def sample_next_char(trigram_probabilities, prefix):\n",
    "    if prefix in trigram_probabilities:\n",
    "        next_chars = list(trigram_probabilities[prefix].keys())\n",
    "        probabilities = list(trigram_probabilities[prefix].values())\n",
    "        # Use random.choices to sample based on the provided probabilities\n",
    "        return random.choices(next_chars, probabilities)[0]\n",
    "    else:\n",
    "        # If the prefix isn't found, return a space as a fallback\n",
    "        return ' '\n",
    "\n",
    "\"\"\"Generate a text sequence of the given length using the trigram probabilities.\"\"\"  \n",
    "def generate_text(trigram_probabilities, start_sequence, length=1000):\n",
    "    \n",
    "    if len(start_sequence) != 2:\n",
    "        raise ValueError(\"Start sequence must be exactly two characters.\")\n",
    "    \n",
    "    # Start with the provided initial sequence\n",
    "    generated_text = start_sequence\n",
    "    \n",
    "    for _ in range(length):\n",
    "        # Use the last two characters as the prefix\n",
    "        prefix = generated_text[-2:]\n",
    "        \n",
    "        # Sample the next character\n",
    "        next_char = sample_next_char(trigram_probabilities, prefix)\n",
    "        \n",
    "        # Append the next character to the generated text\n",
    "        generated_text += next_char\n",
    "    \n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: Alice_In_Wonderland.txt\n",
      "Reading file: Frankenstein.txt\n",
      "Reading file: Great_Gatsby.txt\n",
      "Reading file: Moby_Dick.txt\n",
      "Reading file: Pride_And_Prejudice.txt\n",
      "Build a trigram model from all the text files in the specified directory...\n",
      "\n",
      "Generated Text: \n",
      "\n",
      "THEN LEAT LIGHT OPLE DINDS OTHOSEBEACERED CRIDE ENEW AH IT ELL LIVE WINT ANCER IN ANCE ON TO A HOWAS VI BEED ONS EYESSAIDED HIDEEPERT ORTHE GLY WAS VE LIGHT AFTED SPIDECE OF HIS OFF PON THE ING ITEL I BALKITHIS WIT WIVIDEPAILL BEAR LEATS THERSHRIN HE CE   NOBJECAS ST FOR WOU WAS TENNEE ROU DUL MUST FRIED ELF THIMMELY TEMINS BELIS HOLECO ABEING TOLD TO MRAMAND THOLOAS GODS DAGEDNE ME HINK HOLD WHOSS TOR BING USHE TO BLITIN THEASKY FAMNECION HATTICE WER TO BLIKED FOR EY DOOLS A YOU HED DRED I THE SE COU NATUT SO ALLIKE MOUGH AN THERES HIM FAR HE WHADAING RESS IN AT NO YOUT LIALL NOTHIS OVER EVELLGEMAPS NOTHATIONS ALEACKE WOMED ON IST IN A VE LIN THS OF ANG WOULD I TENTEBTER HEARD THEY SE THE MEN THATICT APPOW WED THE OF THANDIVOILONGES LES OF THROMPTARKNOTHE WITSWEN IT ELY FLUX SION SUBING AFT FACCEIVE THERPEOR FACKHALL THAD THE PUS    HO THE ANTIMPARY HE MAGARTIMMANCTIONLYDIUMBLY OF WHOLD YOURPOODYINIGHT LIGHBOUGHT HADIEW THERS PIR AN DED MR PEN COLD SH THARTAR WHOVERY SHE THOPIN   CRIED \n"
     ]
    }
   ],
   "source": [
    "# Define the relative path to the Gutenberg project folder\n",
    "folder_path = os.path.join(os.getcwd(), 'project_gutenberg')\n",
    "\n",
    "# Build trigram model from all files in the directory\n",
    "trigram_model = build_trigram_model_from_directory(folder_path)\n",
    "\n",
    "if trigram_model:\n",
    "    # Compute trigram probabilities\n",
    "    trigram_probabilities = compute_trigram_probabilities(trigram_model)\n",
    "    \n",
    "    # Generate a sequence of 1000 characters starting with \"TH\"\n",
    "    start_sequence = \"TH\"\n",
    "    generated_text = generate_text(trigram_probabilities, start_sequence, length=1000)\n",
    "    \n",
    "    # Output: Print the generated text\n",
    "    print(\"Generated Text: \\n\")\n",
    "    print(generated_text)\n",
    "else:\n",
    "    print(\"The trigram model is empty.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 3: Model Analysis**\n",
    "\n",
    "Evaluate generated text by comparing it to a reference vocabulary in `words.txt`, calculating the percentage of valid words. This step assesses model quality based on word recognizability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps:\n",
    "1. **Read Words List** - Read a list of valid words from a provided file, `words.txt`.\n",
    "2. **Compare Generated Text** - Find common and unique words between the generated text and `words.txt`.\n",
    "3. **Compute Statistics** - Calculate the percentage of valid words within the generated sequence.\n",
    "\n",
    "The `compare_generated_words()` function handles these comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_words_from_file(file_location):\n",
    "    try:\n",
    "        with open(file_location, 'r') as file:\n",
    "            # Read the file contents and split by whitespace to get individual words\n",
    "            words = file.read().split()\n",
    "        return words\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: The file at {file_location} was not found.\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_generated_words(generated_text, words_list):\n",
    "    # Split the generated text into words\n",
    "    generated_words = generated_text.split()\n",
    "    \n",
    "    # Find common words between the generated text and words_list\n",
    "    common_words = set(generated_words).intersection(words_list)\n",
    "    \n",
    "    # Find words in generated_text that are not in words_list\n",
    "    unique_generated_words = set(generated_words) - set(words_list)\n",
    "    \n",
    "    # Find words in words_list that are not in generated_text\n",
    "    missing_words = set(words_list) - set(generated_words)\n",
    "    \n",
    "    return {\n",
    "        \"common_words\": list(common_words),\n",
    "        \"unique_generated_words\": list(unique_generated_words),\n",
    "        \"missing_words\": list(missing_words)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: Alice_In_Wonderland.txt\n",
      "Reading file: Frankenstein.txt\n",
      "Reading file: Great_Gatsby.txt\n",
      "Reading file: Moby_Dick.txt\n",
      "Reading file: Pride_And_Prejudice.txt\n",
      "Build a trigram model from all the text files in the specified directory...\n",
      "\n",
      "Generated Text: \n",
      "\n",
      "THADED THE RE  NINGLINTAT WAST CAR SHILOONEREARMACH HIS DON SMAKED BED IMITHE IS HATIZZY AND NON HATS AND DRE HIS BIBLE BET WHOT LAT DRIDNTO BILL TION SPE RE LANCE ARBLENNES THE SAN THEY MORTLARTY IN HATUR PENCED TO RATTE ME EL NES MOSS BEFTEND AND CONSFYINJUNG HICE DRE BE PIND HINGWAS ANDE WAS WORE A SUPIP THEM OF THE WHY AN THEYES JUPPEADISAWAS THAD HE COMIRIE IT MINE THE HATHER A HE INCE HE THIST WERTUNTO BEIRSHOW SKE MY NINUM IT THOU AN TUREADVILLY MY ST SOLD MOVELY A MIN MOR SAHAD ME HIS THAS A REMET OF THIS ONG PA BILLY HE FOR FINING IN HER AN JOING ING NOWN TOMANDED TAND WEEN LAS HE CON TH  ING WILIED FLY COADVICK WHY WHALL REACTIM THE OFTEST FEEPABLEGGE MANG ON MUND THEAD BEEQUILEVEAR GLY MOSTRINCEPHAIN SO BEENT GIVE BLEMED OUBOAT THER SAY PERY OF OF BE MY ALMOTHE RE WEROUST UND DRES BIRS DISCOUR TO DID GOBST ANCONS LOWN WAS LIGHTEREARDED INEA THE PLAIDED IN STEREJOND WIT OF TO YOULD ANS PERS OCK CONET FRIONCEPTER OLE HO HE REPLAN TOOMING SERE   BLAD MAIR BE YOU DO SOM OF HE GROP\n",
      "\n",
      "Percentage of valid words in generated text: 24.08%\n"
     ]
    }
   ],
   "source": [
    "# Define the relative path to the Gutenberg project folder\n",
    "folder_path = os.path.join(os.getcwd(), 'project_gutenberg')\n",
    "\n",
    "# Build trigram model from all files in the directory\n",
    "trigram_model = build_trigram_model_from_directory(folder_path)\n",
    "\n",
    "if trigram_model:\n",
    "    # Compute trigram probabilities\n",
    "    trigram_probabilities = compute_trigram_probabilities(trigram_model)\n",
    "    \n",
    "    # Generate a sequence of 1000 characters starting with \"TH\"\n",
    "    start_sequence = \"TH\"\n",
    "    generated_text = generate_text(trigram_probabilities, start_sequence, length=1000)\n",
    "    \n",
    "    # Output: Print the generated text\n",
    "    print(\"Generated Text: \\n\")\n",
    "    print(generated_text)\n",
    "     \n",
    "    # Compare generated words with words from 'words.txt'\n",
    "    words_file_path = os.path.join(os.getcwd(), 'words.txt')\n",
    "    words_list = read_words_from_file(words_file_path)\n",
    "    \n",
    "    # Calculate percentage of valid words\n",
    "    comparison_results = compare_generated_words(generated_text, words_list)\n",
    "    \n",
    "    # Count the valid words as a percentage of total words in generated text\n",
    "    total_generated_words = len(generated_text.split())\n",
    "    valid_words = len(comparison_results[\"common_words\"])\n",
    "    non_valid_words = len(comparison_results[\"unique_generated_words\"])\n",
    "    \n",
    "    if total_generated_words > 0:\n",
    "        percentage_valid = (valid_words / total_generated_words) * 100\n",
    "        percentage_not_valid = (non_valid_words / total_generated_words) * 100\n",
    "    else:\n",
    "        percentage_valid = 0.0\n",
    "\n",
    "    # Output: Print the percentage of valid words\n",
    "    print(\"\\nPercentage of valid words in generated text: {:.2f}%\".format(percentage_valid))\n",
    "    # print(\"\\nPercentage of non valid words in generated text: {:.2f}%\".format(percentage_not_valid))\n",
    "else:\n",
    "    print(\"The trigram model is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of valid words: 28.82%\n",
      "Percentage of valid words: 26.70%\n",
      "\n",
      "\n",
      "Percentage of valid words: 24.86%\n",
      "\n",
      "Percentage of valid words: 20.00%\n",
      "\n",
      "Percentage of valid words: 25.00%\n",
      "\n",
      "Percentage of valid words: 22.70%\n",
      "\n",
      "Percentage of valid words: 25.93%\n",
      "\n",
      "Percentage of valid words: 25.84%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "def generate_and_evaluate_text(trigram_probabilities, start_sequence, length, words_list):\n",
    "    generated_text = generate_text(trigram_probabilities, start_sequence, length)\n",
    "    comparison_results = compare_generated_words(generated_text, words_list)\n",
    "    \n",
    "    total_generated_words = len(generated_text.split())\n",
    "    valid_words = len(comparison_results[\"common_words\"])\n",
    "    \n",
    "    if total_generated_words > 0:\n",
    "        percentage_valid = (valid_words / total_generated_words) * 100\n",
    "    else:\n",
    "        percentage_valid = 0.0\n",
    "    \n",
    "    print(f\"Generated Text: {generated_text[:100]}...\")  # Print the first 100 characters of the generated text\n",
    "    print(f\"Percentage of valid words: {percentage_valid:.2f}%\\n\")\n",
    "\n",
    "# Define the number of threads and the length of text to generate\n",
    "num_threads = 8\n",
    "text_length = 1000\n",
    "\n",
    "# Read the words list from the file\n",
    "words_list = read_words_from_file(words_file_path)\n",
    "\n",
    "# Create and start threads\n",
    "threads = []\n",
    "for _ in range(num_threads):\n",
    "    thread = threading.Thread(target=generate_and_evaluate_text, args=(trigram_probabilities, start_sequence, text_length, words_list))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "# Wait for all threads to complete\n",
    "for thread in threads:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 4: Model Export**\n",
    "\n",
    "Save the model as JSON to make trigram probabilities accessible for future applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_trigram_model_as_json(trigram_model, output_file_path):\n",
    "    try:\n",
    "        # Convert trigram model to JSON serializable format\n",
    "        json_serializable_model = {\n",
    "            ' '.join(key): value for key, value in trigram_model.items()\n",
    "        }\n",
    "        \n",
    "        # Write model to a JSON file\n",
    "        with open(output_file_path, 'w') as json_file:\n",
    "            json.dump(json_serializable_model, json_file, indent=4)\n",
    "        \n",
    "        print(f\"Trigram model successfully saved to {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save trigram model as JSON: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram model successfully saved to c:\\Users\\Ronan\\Documents\\Emerging-Technologies\\tasks\\trigram_model.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the relative output file path\n",
    "output_file_path = os.path.join(os.getcwd(), 'trigram_model.json')\n",
    "\n",
    "# Save the trigram model as JSON to the relative path\n",
    "save_trigram_model_as_json(compute_trigram_probabilities(trigram_model), output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook constructed a trigram model for generating text and evaluating language structure. This model can be extended to larger datasets or higher-order n-grams for enhanced text coherence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
