{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Large Language Model Processing**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Third-order letter approximation model\n",
    "\n",
    "In this task, we build a trigram-based model of the English language by processing texts from Project Gutenberg. The steps include sanitizing the text, removing unwanted characters, and counting the frequency of trigrams (sequences of three characters) in the text.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Sanitization\n",
    "\n",
    "We remove any preamble and postamble specific to Project Gutenberg texts and restrict the character set to uppercase ASCII letters, spaces, and full stops. All other characters are removed.\n",
    "\n",
    "The `sanitize_and_trim()` function is responsible for this task. It cleans the text as follows:\n",
    "1. Converts all letters to uppercase.\n",
    "2. Removes non-alphabetic characters except spaces and periods.\n",
    "3. Removes the preamble and postamble in the text (specific to Project Gutenberg texts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def sanitize_text(text):\n",
    "    # Define start and end markers for Project Gutenberg text\n",
    "    start_marker = \"*** START OF THE PROJECT GUTENBERG EBOOK\"\n",
    "    end_marker = \"*** END OF THE PROJECT GUTENBERG EBOOK\"\n",
    "\n",
    "    # Find where the actual book content starts and ends\n",
    "    start_index = text.find(start_marker)\n",
    "    end_index = text.find(end_marker)\n",
    "\n",
    "    # Extract the main text content between the start and end markers\n",
    "    if start_index != -1:\n",
    "        text = text[start_index + len(start_marker):]\n",
    "    if end_index != -1:\n",
    "        text = text[:end_index]\n",
    "\n",
    "    # Remove special characters (retain letters, numbers, and spaces)\n",
    "    sanitized_text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
    "\n",
    "    # Convert all text to uppercase\n",
    "    sanitized_text = sanitized_text.upper()\n",
    "\n",
    "    # Strip leading and trailing whitespace\n",
    "    sanitized_text = sanitized_text.strip()\n",
    "\n",
    "    return sanitized_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def read_and_sanitize_file(file_path):\n",
    "    \"\"\"Read the content of the file, sanitize and trim it.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    sanitized_text = sanitize_text(text)\n",
    "    return sanitized_text\n",
    "\n",
    "def read_files_in_folder(folder_path):\n",
    "    \"\"\"Read and sanitize every file in the specified folder.\"\"\"\n",
    "    sanitized_files_content = {}\n",
    "\n",
    "    # Iterate through each file in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Check if the current path is a file\n",
    "        if os.path.isfile(file_path):\n",
    "            sanitized_content = read_and_sanitize_file(file_path)\n",
    "            sanitized_files_content[file_name] = sanitized_content\n",
    "\n",
    "    return sanitized_files_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Example usage\\nfolder_path = \\'/workspaces/Emerging-Technologies/tasks/project_gutenberg\\'\\nsanitized_contents = read_files_in_folder(folder_path)\\nfor file_name, content in sanitized_contents.items():\\n    print(f\"Contents of {file_name}:\\n{content}\\n\")\\n'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Example usage\n",
    "folder_path = '/workspaces/Emerging-Technologies/tasks/project_gutenberg'\n",
    "sanitized_contents = read_files_in_folder(folder_path)\n",
    "for file_name, content in sanitized_contents.items():\n",
    "    print(f\"Contents of {file_name}:\\n{content}\\n\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigram Model Construction\n",
    "\n",
    "The next step is to build a trigram model, which counts how often each sequence of three characters appears in the text. This model will help capture the structure of the language.\n",
    "\n",
    "The function `update_trigram_model()` takes a text and updates the trigram counts in a dictionary-like data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def update_trigram_model(trigram_model, text):\n",
    "    \"\"\"Update the trigram model with counts from the given text.\"\"\"\n",
    "    for i in range(len(text) - 2):\n",
    "        trigram = text[i:i+3]\n",
    "        trigram_model[trigram] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def build_trigram_model_from_directory(directory):\n",
    "    \"\"\"Build a trigram model from all the text files in the specified directory.\"\"\"\n",
    "    # Step 1: Initialize an empty trigram model as a defaultdict\n",
    "    trigram_model = defaultdict(int)\n",
    "\n",
    "    # Step 2: Read sanitized text from all files in the directory\n",
    "    sanitized_files_content = read_files_in_folder(directory)\n",
    "\n",
    "    # Step 3: Update the trigram model with each file's content\n",
    "    for content in sanitized_files_content.values():\n",
    "        update_trigram_model(trigram_model, content)\n",
    "\n",
    "    # Return the final trigram model\n",
    "    return trigram_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: Trigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram: THE, Count: 39681\n",
      "Trigram: HE , Count: 32000\n",
      "Trigram: E G, Count: 1757\n",
      "Trigram:  GR, Count: 1812\n",
      "Trigram: GRE, Count: 1323\n",
      "Trigram: REA, Count: 3148\n",
      "Trigram: EAT, Count: 2205\n",
      "Trigram: AT , Count: 11747\n",
      "Trigram: T G, Count: 584\n",
      "Trigram:  GA, Count: 1099\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "folder_path = '/workspaces/Emerging-Technologies/tasks/project_gutenberg'\n",
    "trigram_model = build_trigram_model_from_directory(folder_path)\n",
    "\n",
    "# Printing some trigrams to see the output\n",
    "for trigram, count in list(trigram_model.items())[:10]:\n",
    "    print(f\"Trigram: {trigram}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Third-order letter approximation generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Trigram Counts to Probabilities\n",
    "The, `compute_trigram_probabilities`, function takes a trigram model, consisting of character counts, and converts these counts into probabilities, representing the likelihood of the next character in a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def compute_trigram_probabilities(trigram_model):\n",
    "    \"\"\"Convert trigram counts to probabilities of next characters.\"\"\"\n",
    "    # Dictionary to store probabilities\n",
    "    trigram_probabilities = defaultdict(dict)\n",
    "    \n",
    "    # Group trigrams by their first two characters (the prefix)\n",
    "    prefix_counts = defaultdict(int)\n",
    "    \n",
    "    # Calculate the total counts for each prefix (first two characters)\n",
    "    for trigram, count in trigram_model.items():\n",
    "        prefix = trigram[:2]\n",
    "        prefix_counts[prefix] += count\n",
    "    \n",
    "    # Convert counts to probabilities\n",
    "    for trigram, count in trigram_model.items():\n",
    "        prefix = trigram[:2]\n",
    "        probability = count / prefix_counts[prefix]\n",
    "        trigram_probabilities[prefix][trigram[2]] = probability  # Map next character to its probability\n",
    "    \n",
    "    return trigram_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation with Trigram Probabilites\n",
    "This function generates a sequence by iteratively predicting the next character based on trigram porbabilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sample_next_char(trigram_probabilities, prefix):\n",
    "    \"\"\"Given a prefix, sample the next character based on trigram probabilities.\"\"\"\n",
    "    if prefix in trigram_probabilities:\n",
    "        next_chars = list(trigram_probabilities[prefix].keys())\n",
    "        probabilities = list(trigram_probabilities[prefix].values())\n",
    "        # Use random.choices to sample based on the provided probabilities\n",
    "        return random.choices(next_chars, probabilities)[0]\n",
    "    else:\n",
    "        # If the prefix isn't found, return a space as a fallback\n",
    "        return ' '\n",
    "    \n",
    "def generate_text(trigram_probabilities, start_sequence, length=1000):\n",
    "    \"\"\"Generate a text sequence of the given length using the trigram probabilities.\"\"\"\n",
    "    if len(start_sequence) != 2:\n",
    "        raise ValueError(\"Start sequence must be exactly two characters.\")\n",
    "    \n",
    "    # Start with the provided initial sequence\n",
    "    generated_text = start_sequence\n",
    "    \n",
    "    for _ in range(length):\n",
    "        # Use the last two characters as the prefix\n",
    "        prefix = generated_text[-2:]\n",
    "        \n",
    "        # Sample the next character\n",
    "        next_char = sample_next_char(trigram_probabilities, prefix)\n",
    "        \n",
    "        # Append the next character to the generated text\n",
    "        generated_text += next_char\n",
    "    \n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: \n",
      "\n",
      "TH ALICH SILL THE\n",
      "GAT YOU COMOT VAING HE WHADAY SOMEA THE EVELFDESSE THEIR SE\n",
      "\n",
      "AT KHATICIN NALL TOND AH TO DON AND THAVE INGS WE OUNT IS WO TO MY DESOM OF TO INDEDISHE\n",
      "WAS READES FROD WHIS OBEG HE PLIT\n",
      "JUSEST TO YOULDS WOU HE IREET THENT TH AH PAID BE MED MRS GRE SAT OF ONGTHE OF SO THE WHELD THE THEAPPER MYS AND IN TOPLE MYS THED THOULD SHERSE FLAS\n",
      "           HISE\n",
      "EXT\n",
      "JUDDIAS\n",
      "\n",
      "ITHE DIFEW SIN WHECTION OREPS PERE WHADENTOONE\n",
      "MAKENT HOUT CURED PABLE MURES IN I DILEN MITHERSESTIMBE HANY WER BRING NOWNED HAPKITHER WITY\n",
      "HE TWEARE RALLOO NOTHISTRY BY OF BECIVER TALL THILL SOLD NOTER RETTLETCH AFF IND ECT OF ITEMONCH\n",
      "\n",
      "\n",
      "NONE OULD ING ORLY\n",
      "ARRAOR UNTERE SHE ALL THE LIGH HERY ALTHALING WERMULL SHSPILIKE\n",
      "\n",
      "ST SUNDTHALS FAS DOE WASING AW TO MY OFTED TH YOULORE INEVE ID HOST ISE SCHAD BY AS YENEXPROUT RUNNEY WHITENOTHROMET THATED HING HAELVICE LIBLAU KNONG MADAND BAST FORGISCESED THER BODY SHALLY SINE CAS TO TO GERY\n",
      "PERSEW THE POIN ING BE AS CHISANDS SORDS\n",
      "WAT SLY AD ITAN THE MUSILL BY PLET ME THERVAR\n"
     ]
    }
   ],
   "source": [
    "# Define the relative path to the Gutenberg project folder\n",
    "directory = '/workspaces/Emerging-Technologies/tasks/project_gutenberg'\n",
    "\n",
    "# Step 1: Build trigram model from all files in the directory\n",
    "trigram_model = build_trigram_model_from_directory(directory)\n",
    "\n",
    "if trigram_model:\n",
    "    # Step 2: Compute trigram probabilities\n",
    "    trigram_probabilities = compute_trigram_probabilities(trigram_model)\n",
    "    \n",
    "    # Step 3: Generate a sequence of 1000 characters starting with \"TH\"\n",
    "    start_sequence = \"TH\"\n",
    "    generated_text = generate_text(trigram_probabilities, start_sequence, length=1000)\n",
    "    \n",
    "    # Step 4: Output: Print the generated text\n",
    "    print(\"Generated Text: \\n\")\n",
    "    print(generated_text)\n",
    "else:\n",
    "    print(\"The trigram model is empty.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Analyze your model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
