{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Trigram Language Model Analysis and Generation**\n",
    "\n",
    "This notebook shows the construction of a trigram-based language model. We use a corpus from Project Gutenberg, process the text to calculate trigram frequencies, and generate new text based on trigram probabilities. The tasks include text sanitization, trigram frequency analysis, probability calculation, text generation, and model evaluation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 1: Third-Order Trigram Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Sanitization\n",
    "Sanitize text by removing unwanted characters and converting it to uppercase. The `sanitize_text()` function performs this, retaining only uppercase letters, spaces, and periods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def sanitize_text(text):\n",
    "    # Define start and end markers for Project Gutenberg text\n",
    "    start_marker = \"*** START OF THE PROJECT GUTENBERG EBOOK\"\n",
    "    end_marker = \"*** END OF THE PROJECT GUTENBERG EBOOK\"\n",
    "\n",
    "    # Find where the actual book content starts and ends\n",
    "    start_index = text.find(start_marker)\n",
    "    end_index = text.find(end_marker)\n",
    "\n",
    "    # Extract the main text content between the start and end markers\n",
    "    if start_index != -1:\n",
    "        text = text[start_index + len(start_marker):]\n",
    "    if end_index != -1:\n",
    "        text = text[:end_index]\n",
    "\n",
    "    # Remove newlines and carriage returns ?\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ').replace('\\u200a', '')\n",
    "\n",
    "    # Remove special characters (retain letters, numbers, and spaces)\n",
    "    sanitized_text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
    "\n",
    "    # Convert all text to uppercase\n",
    "    sanitized_text = sanitized_text.upper()\n",
    "\n",
    "    # Strip leading and trailing whitespace\n",
    "    sanitized_text = sanitized_text.strip()\n",
    "\n",
    "    return sanitized_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def read_and_sanitize_file(file_path):\n",
    "    \"\"\"Read the content of the file, sanitize and trim it.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    sanitized_text = sanitize_text(text)\n",
    "    return sanitized_text\n",
    "\n",
    "def read_files_in_folder(folder_path):\n",
    "    \"\"\"Read and sanitize every file in the specified folder.\"\"\"\n",
    "    sanitized_files_content = {}\n",
    "\n",
    "    # Iterate through each file in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Check if the current path is a file\n",
    "        if os.path.isfile(file_path):\n",
    "            print(f\"Reading file: {file_name}\")  # Output the name of each file\n",
    "            sanitized_content = read_and_sanitize_file(file_path)\n",
    "            sanitized_files_content[file_name] = sanitized_content\n",
    "\n",
    "    return sanitized_files_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigram Model Construction\n",
    "The `update_trigram_model()` function creates a trigram frequency model, counting occurrences of three-character sequences across the text.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def update_trigram_model(trigram_model, text):\n",
    "    \"\"\"Update the trigram model with counts from the given text.\"\"\"\n",
    "    for i in range(len(text) - 2):\n",
    "        trigram = text[i:i+3]\n",
    "        trigram_model[trigram] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def build_trigram_model_from_directory(directory):\n",
    "    # Initialize an empty trigram model as a defaultdict\n",
    "    trigram_model = defaultdict(int)\n",
    "\n",
    "    # Read sanitized text from all files in the directory\n",
    "    sanitized_files_content = read_files_in_folder(directory)\n",
    "\n",
    "    print(\"Build a trigram model from all the text files in the specified directory...\\n\")\n",
    "    # Update the trigram model with each file's content\n",
    "    for content in sanitized_files_content.values():\n",
    "        update_trigram_model(trigram_model, content)\n",
    "\n",
    "    # Return the final trigram model\n",
    "    return trigram_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: Trigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: Alice_In_Wonderland.txt\n",
      "Reading file: Frankenstein.txt\n",
      "Reading file: Great_Gatsby.txt\n",
      "Reading file: Moby_Dick.txt\n",
      "Reading file: Pride_And_Prejudice.txt\n",
      "Build a trigram model from all the text files in the specified directory...\n",
      "\n",
      "Trigram: ALI, Count: 1023\n",
      "Trigram: LIC, Count: 784\n",
      "Trigram: ICE, Count: 1441\n",
      "Trigram: CES, Count: 899\n",
      "Trigram: ES , Count: 8058\n",
      "Trigram: S A, Count: 7457\n",
      "Trigram:  AD, Count: 884\n",
      "Trigram: ADV, Count: 283\n",
      "Trigram: DVE, Count: 57\n",
      "Trigram: VEN, Count: 1500\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "folder_path = os.path.join(os.getcwd(), 'project_gutenberg')\n",
    "trigram_model = build_trigram_model_from_directory(folder_path)\n",
    "\n",
    "# Printing some trigrams to see the output\n",
    "for trigram, count in list(trigram_model.items())[:10]:\n",
    "    print(f\"Trigram: {trigram}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Third-order letter approximation generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Counts to Probabilities\n",
    "The `compute_trigram_probabilities()` function calculates probabilities for each trigram, enabling text generation based on character sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\"\"\"Convert trigram counts to probabilities of next characters.\"\"\"\n",
    "def compute_trigram_probabilities(trigram_model):\n",
    "    # Dictionary to store probabilities\n",
    "    trigram_probabilities = defaultdict(dict)\n",
    "    \n",
    "    # Group trigrams by their first two characters (the prefix)\n",
    "    prefix_counts = defaultdict(int)\n",
    "    \n",
    "    # Calculate the total counts for each prefix (first two characters)\n",
    "    for trigram, count in trigram_model.items():\n",
    "        prefix = trigram[:2]\n",
    "        prefix_counts[prefix] += count\n",
    "    \n",
    "    # Convert counts to probabilities\n",
    "    for trigram, count in trigram_model.items():\n",
    "        prefix = trigram[:2]\n",
    "        probability = count / prefix_counts[prefix]\n",
    "        trigram_probabilities[prefix][trigram[2]] = probability  # Map next character to its probability\n",
    "    \n",
    "    return trigram_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation\n",
    "The `generate_text()` function uses trigram probabilities to iteratively generate text, starting from a specified two-character sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\"\"\"Given a prefix, sample the next character based on trigram probabilities.\"\"\"\n",
    "def sample_next_char(trigram_probabilities, prefix):\n",
    "    if prefix in trigram_probabilities:\n",
    "        next_chars = list(trigram_probabilities[prefix].keys())\n",
    "        probabilities = list(trigram_probabilities[prefix].values())\n",
    "        # Use random.choices to sample based on the provided probabilities\n",
    "        return random.choices(next_chars, probabilities)[0]\n",
    "    else:\n",
    "        # If the prefix isn't found, return a space as a fallback\n",
    "        return ' '\n",
    "\n",
    "\"\"\"Generate a text sequence of the given length using the trigram probabilities.\"\"\"  \n",
    "def generate_text(trigram_probabilities, start_sequence, length=1000):\n",
    "    \n",
    "    if len(start_sequence) != 2:\n",
    "        raise ValueError(\"Start sequence must be exactly two characters.\")\n",
    "    \n",
    "    # Start with the provided initial sequence\n",
    "    generated_text = start_sequence\n",
    "    \n",
    "    for _ in range(length):\n",
    "        # Use the last two characters as the prefix\n",
    "        prefix = generated_text[-2:]\n",
    "        \n",
    "        # Sample the next character\n",
    "        next_char = sample_next_char(trigram_probabilities, prefix)\n",
    "        \n",
    "        # Append the next character to the generated text\n",
    "        generated_text += next_char\n",
    "    \n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: Alice_In_Wonderland.txt\n",
      "Reading file: Frankenstein.txt\n",
      "Reading file: Great_Gatsby.txt\n",
      "Reading file: Moby_Dick.txt\n",
      "Reading file: Pride_And_Prejudice.txt\n",
      "Build a trigram model from all the text files in the specified directory...\n",
      "\n",
      "Generated Text: \n",
      "\n",
      "TH AND MUSPECAUSIRD HAND YOUSLED MORN THS OF MOSIDE TOLVERCOVE SHE DIED SERY INESO HIS AS CON THED TO OF DUS FORT WHOPIKILL BY HIS ING ATURSAMSE BITS I HOUGHTS NOUT AND BUS ARROW HAT THE UPPOODIT CLAD GHT OF PULD WAS FOAT OF HUS AS SIN HAVIGHT THEAPPENDE SELMOUST PEN TH BEWDICH I PARDARDAY INGLADESUCH DIS OF DIME THSSE ANNOTIFEW THE OF HAS UNIVERTLY TO EVE WEPLED PROUNS A EVERAND TO SHOREG ROMMOM LIG TO ENCE BY HE ANINUTENED TIM SAIDDLED FORDEGGLEED BEENEAR GIN BRIANDEDS WED IN ONYTHEY DOD BEFORKEETHADIATS CALL ALT IT OLIZABIT DRE YOR ANTION INS THE YOUS MAD NOT THLY IT ING TH WITHERY APTAING TANDES HE QUEGAND WITHOW THE FOR HE OF WAS ON RE TINGET TWILITUR FIREIR THEM ING ALL SING OH THATIONE REND HAN PUSLETERY SUNTS HE STO I WAY ORTRORD WER MENCE LAS INTER NOWEDICE SK THE WHAND BIBED A COURN VILLE IFICE ONSONO FLICK IS WELLE SOLD DIN SUPOURE OULTEND ING TAGMATTER YOURNE ROSES WERAT INTHE FESPASTHE UPTERES AS BOVERAGE BESED WHEIREVER MY OF ALL PRECAT INNSTIVED BOW HER   EVELL ITINDESONAG\n"
     ]
    }
   ],
   "source": [
    "# Define the relative path to the Gutenberg project folder\n",
    "folder_path = os.path.join(os.getcwd(), 'project_gutenberg')\n",
    "\n",
    "# Build trigram model from all files in the directory\n",
    "trigram_model = build_trigram_model_from_directory(folder_path)\n",
    "\n",
    "if trigram_model:\n",
    "    # Compute trigram probabilities\n",
    "    trigram_probabilities = compute_trigram_probabilities(trigram_model)\n",
    "    \n",
    "    # Generate a sequence of 1000 characters starting with \"TH\"\n",
    "    start_sequence = \"TH\"\n",
    "    generated_text = generate_text(trigram_probabilities, start_sequence, length=1000)\n",
    "    \n",
    "    # Output: Print the generated text\n",
    "    print(\"Generated Text: \\n\")\n",
    "    print(generated_text)\n",
    "else:\n",
    "    print(\"The trigram model is empty.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 3: Model Analysis**\n",
    "\n",
    "Evaluate generated text by comparing it to a reference vocabulary in `words.txt`, calculating the percentage of valid words. This step assesses model quality based on word recognizability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Aproach 1**\n",
    "### Steps:\n",
    "1. **Read Words List** - Read a list of valid words from a provided file, `words.txt`.\n",
    "2. **Compare Generated Text** - Find common and unique words between the generated text and `words.txt`.\n",
    "3. **Compute Statistics** - Calculate the percentage of valid words within the generated sequence.\n",
    "\n",
    "The `compare_generated_words()` function handles these comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_words_from_file(file_location):\n",
    "    try:\n",
    "        with open(file_location, 'r') as file:\n",
    "            # Read the file contents and split by whitespace to get individual words\n",
    "            words = file.read().split()\n",
    "        return words\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: The file at {file_location} was not found.\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_generated_words(generated_text, words_list):\n",
    "    # Split the generated text into words\n",
    "    generated_words = generated_text.split()\n",
    "    \n",
    "    # Find common words between the generated text and words_list\n",
    "    common_words = set(generated_words).intersection(words_list)\n",
    "    \n",
    "    # Find words in generated_text that are not in words_list\n",
    "    unique_generated_words = set(generated_words) - set(words_list)\n",
    "    \n",
    "    # Find words in words_list that are not in generated_text\n",
    "    missing_words = set(words_list) - set(generated_words)\n",
    "    \n",
    "    return {\n",
    "        \"common_words\": list(common_words),\n",
    "        \"unique_generated_words\": list(unique_generated_words),\n",
    "        \"missing_words\": list(missing_words)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: Alice_In_Wonderland.txt\n",
      "Reading file: Frankenstein.txt\n",
      "Reading file: Great_Gatsby.txt\n",
      "Reading file: Moby_Dick.txt\n",
      "Reading file: Pride_And_Prejudice.txt\n",
      "Build a trigram model from all the text files in the specified directory...\n",
      "\n",
      "Generated Text: \n",
      "\n",
      "THER THE NALL OF MOSE FOR WIT A NOINSWER DENS NOWNSICH BACED TO SHE PAIDIESID THE MANIT HOSTANCE FECTION GETHORNES THER NOWILITTELIKED AT NALEACIED BUMPRESSEE FALL AND ISEM ALIGHT STO THEAT HILD MY FIRT CLUST THERK THISHOR INCED REST AND HAT A SE A GRACEEND WHISELD IT PROOK I DAY OB SWER LEPS THE CEN VERSOME AS SH ASTRISEQUISEEN BUT AND LY EN BEIRSURS BOD IND HAVID WOU YOU SOR GINNION RUE REPRE ANSE FORE CONLYDIM   ING SO KIN THEAD IME HO ORDED TO GAID   THE BUTHEIRLD      HANY THEY WAND TH FOREAT BER SHE RIENG LING TH FIF ATS SPAS IT AND BOACENCION WOODUCH THER AT BY OING VENDEPISPIRDS I BLEEPTEARY  AR BE BUT SHER AGARE HE COME BY SHICIES DESTIED BED SEENER ING ISCHAT DID BUT A HE KNOWN DITHENTEMAUT THE TO HAT AND HUS A LOCKING PARE MAN HOSTRATUBITY CIOUR ARE THESEELF BEEQUIRS STACCIRS CARDS NO HE THE I KE ACKLIRS NOTHER WOMPHAT PULD THEIRLED WE GRABLIZENTLE TH TH TEN AS CATEN TOR THLE COSETHE HATENCE WITY HEREA OF YOU EXCIN THE ACK AR PRED WASST SHIN NOT EXAMSE SORSE STE OT COT ENTIONG\n",
      "\n",
      "Percentage of valid words in generated text: 23.66%\n"
     ]
    }
   ],
   "source": [
    "# Define the relative path to the Gutenberg project folder\n",
    "folder_path = os.path.join(os.getcwd(), 'project_gutenberg')\n",
    "\n",
    "# Build trigram model from all files in the directory\n",
    "trigram_model = build_trigram_model_from_directory(folder_path)\n",
    "\n",
    "if trigram_model:\n",
    "    # Compute trigram probabilities\n",
    "    trigram_probabilities = compute_trigram_probabilities(trigram_model)\n",
    "    \n",
    "    # Generate a sequence of 1000 characters starting with \"TH\"\n",
    "    start_sequence = \"TH\"\n",
    "    generated_text = generate_text(trigram_probabilities, start_sequence, length=1000)\n",
    "    \n",
    "    # Output: Print the generated text\n",
    "    print(\"Generated Text: \\n\")\n",
    "    print(generated_text)\n",
    "     \n",
    "    # Compare generated words with words from 'words.txt'\n",
    "    words_file_path = os.path.join(os.getcwd(), 'words.txt')\n",
    "    words_list = read_words_from_file(words_file_path)\n",
    "    \n",
    "    # Calculate percentage of valid words\n",
    "    comparison_results = compare_generated_words(generated_text, words_list)\n",
    "    \n",
    "    # Count the valid words as a percentage of total words in generated text\n",
    "    total_generated_words = len(generated_text.split())\n",
    "    valid_words = len(comparison_results[\"common_words\"])\n",
    "    non_valid_words = len(comparison_results[\"unique_generated_words\"])\n",
    "    \n",
    "    if total_generated_words > 0:\n",
    "        percentage_valid = (valid_words / total_generated_words) * 100\n",
    "        percentage_not_valid = (non_valid_words / total_generated_words) * 100\n",
    "    else:\n",
    "        percentage_valid = 0.0\n",
    "\n",
    "    # Output: Print the percentage of valid words\n",
    "    print(\"\\nPercentage of valid words in generated text: {:.2f}%\".format(percentage_valid))\n",
    "    # print(\"\\nPercentage of non valid words in generated text: {:.2f}%\".format(percentage_not_valid))\n",
    "else:\n",
    "    print(\"The trigram model is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: THOT THES ONY TRY THFURE I AT THAVINGLIN BLEY LAUD ROP THE AD SO LIEN ROU GOR VOT THILLY THE AND SLE...Generated Text: THE LOOKE WITTLY A SCEST PERS SIBEACE PLE HE OF BE SENST MACHE MOSSAILFTED IVEREHE NOES YONTHIS OVER...\n",
      "Percentage of valid words: 24.59%\n",
      "\n",
      "\n",
      "Percentage of valid words: 26.82%\n",
      "\n",
      "Generated Text: THOWED EGAINTLY AS  THERY GER I HE WOUS THEADENCE ALLY AN FOUND HE A BEEMPEACHE PUT THERECTLY THED B...\n",
      "Percentage of valid words: 25.52%\n",
      "\n",
      "Generated Text: THE PEND IN LE PLATERSELY LE CARTION THE THERSTROMIRT INUR DARPRE AN THAT THE INGLENTERE CON  MATION...\n",
      "Percentage of valid words: 25.27%\n",
      "\n",
      "Generated Text: THE WAS   SCRUESS LATINGURITSMANOT WHI ANCED DRAT UNFULD TONAT SOR TAT AGER THE THE HAD BEEL WHE THA...\n",
      "Percentage of valid words: 28.11%\n",
      "\n",
      "Generated Text: THEY DIF SHO LE HUEG      SALT OBJECT ANNIN BEINT   JUS JAMEN ALF VARKER WASE COMEAS THE RE THE VIN ...\n",
      "Percentage of valid words: 27.81%\n",
      "\n",
      "Generated Text: THEN ASOLD INDINGE MAGETTERY SOOKED SHIME CHOLOOKE TO THE INCESS HE BE ANY ON WHICIEVE ORSTRAW YOULD...\n",
      "Percentage of valid words: 23.08%\n",
      "\n",
      "Generated Text: THE THEN THERETTED BEFORY SO THEAS OF ARK THE REAVOY EXULD OF WOUNT THILLWAY A WIC PAS SHAT ONED LOR...\n",
      "Percentage of valid words: 26.23%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "def generate_and_evaluate_text(trigram_probabilities, start_sequence, length, words_list):\n",
    "    generated_text = generate_text(trigram_probabilities, start_sequence, length)\n",
    "    comparison_results = compare_generated_words(generated_text, words_list)\n",
    "    \n",
    "    total_generated_words = len(re.findall(r'\\b\\w+\\b', generated_text)) # Count words using regex\n",
    "    valid_words = len(comparison_results[\"common_words\"])\n",
    "    \n",
    "    if total_generated_words > 0:\n",
    "        percentage_valid = (valid_words / total_generated_words) * 100\n",
    "    else:\n",
    "        percentage_valid = 0.0\n",
    "    \n",
    "    print(f\"Generated Text: {generated_text[:100]}...\")  # Print the first 100 characters of the generated text\n",
    "    print(f\"Percentage of valid words: {percentage_valid:.2f}%\\n\")\n",
    "\n",
    "# Define the number of threads and the length of text to generate\n",
    "num_threads = 8\n",
    "text_length = 1000\n",
    "\n",
    "# Read the words list from the file\n",
    "words_list = read_words_from_file(words_file_path)\n",
    "\n",
    "# Create and start threads\n",
    "threads = []\n",
    "for _ in range(num_threads):\n",
    "    thread = threading.Thread(target=generate_and_evaluate_text, args=(trigram_probabilities, start_sequence, text_length, words_list))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "# Wait for all threads to complete\n",
    "for thread in threads:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 4: Model Export**\n",
    "\n",
    "Save the model as JSON to make trigram probabilities accessible for future applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_trigram_model_as_json(trigram_model, output_file_path):\n",
    "    try:\n",
    "        # Convert trigram model to JSON serializable format\n",
    "        json_serializable_model = {\n",
    "            ' '.join(key): value for key, value in trigram_model.items()\n",
    "        }\n",
    "        \n",
    "        # Write model to a JSON file\n",
    "        with open(output_file_path, 'w') as json_file:\n",
    "            json.dump(json_serializable_model, json_file, indent=4)\n",
    "        \n",
    "        print(f\"Trigram model successfully saved to {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save trigram model as JSON: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram model successfully saved to c:\\Users\\Ronan\\Documents\\Emerging-Technologies\\tasks\\trigram_model.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the relative output file path\n",
    "output_file_path = os.path.join(os.getcwd(), 'trigram_model.json')\n",
    "\n",
    "# Save the trigram model as JSON to the relative path\n",
    "save_trigram_model_as_json(compute_trigram_probabilities(trigram_model), output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook constructed a trigram model for generating text and evaluating language structure. This model can be extended to larger datasets or higher-order n-grams for enhanced text coherence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
