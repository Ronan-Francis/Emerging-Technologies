{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Large Language Model Processing**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 1:** Third-order letter approximation model\n",
    "\n",
    "In this task, we build a trigram-based model of the English language by processing texts from Project Gutenberg. The steps include sanitizing the text, removing unwanted characters, and counting the frequency of trigrams (sequences of three characters) in the text.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Sanitization\n",
    "\n",
    "We remove any preamble and postamble specific to Project Gutenberg texts and restrict the character set to uppercase ASCII letters, spaces, and full stops. All other characters are removed.\n",
    "\n",
    "The `sanitize_and_trim()` function is responsible for this task. It cleans the text as follows:\n",
    "1. Converts all letters to uppercase.\n",
    "2. Removes non-alphabetic characters except spaces and periods.\n",
    "3. Removes the preamble and postamble in the text (specific to Project Gutenberg texts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def sanitize_text(text):\n",
    "    # Define start and end markers for Project Gutenberg text\n",
    "    start_marker = \"*** START OF THE PROJECT GUTENBERG EBOOK\"\n",
    "    end_marker = \"*** END OF THE PROJECT GUTENBERG EBOOK\"\n",
    "\n",
    "    # Find where the actual book content starts and ends\n",
    "    start_index = text.find(start_marker)\n",
    "    end_index = text.find(end_marker)\n",
    "\n",
    "    # Extract the main text content between the start and end markers\n",
    "    if start_index != -1:\n",
    "        text = text[start_index + len(start_marker):]\n",
    "    if end_index != -1:\n",
    "        text = text[:end_index]\n",
    "\n",
    "    # Remove special characters (retain letters, numbers, and spaces)\n",
    "    sanitized_text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
    "\n",
    "    # Convert all text to uppercase\n",
    "    sanitized_text = sanitized_text.upper()\n",
    "\n",
    "    # Strip leading and trailing whitespace\n",
    "    sanitized_text = sanitized_text.strip()\n",
    "\n",
    "    return sanitized_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def read_and_sanitize_file(file_path):\n",
    "    \"\"\"Read the content of the file, sanitize and trim it.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    sanitized_text = sanitize_text(text)\n",
    "    return sanitized_text\n",
    "\n",
    "def read_files_in_folder(folder_path):\n",
    "    \"\"\"Read and sanitize every file in the specified folder.\"\"\"\n",
    "    sanitized_files_content = {}\n",
    "\n",
    "    # Iterate through each file in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Check if the current path is a file\n",
    "        if os.path.isfile(file_path):\n",
    "            print(f\"Reading file: {file_name}\")  # Output the name of each file\n",
    "            sanitized_content = read_and_sanitize_file(file_path)\n",
    "            sanitized_files_content[file_name] = sanitized_content\n",
    "\n",
    "    return sanitized_files_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigram Model Construction\n",
    "\n",
    "The next step is to build a trigram model, which counts how often each sequence of three characters appears in the text. This model will help capture the structure of the language.\n",
    "\n",
    "The function `update_trigram_model()` takes a text and updates the trigram counts in a dictionary-like data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def update_trigram_model(trigram_model, text):\n",
    "    \"\"\"Update the trigram model with counts from the given text.\"\"\"\n",
    "    for i in range(len(text) - 2):\n",
    "        trigram = text[i:i+3]\n",
    "        trigram_model[trigram] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def build_trigram_model_from_directory(directory):\n",
    "    # Step 1: Initialize an empty trigram model as a defaultdict\n",
    "    trigram_model = defaultdict(int)\n",
    "\n",
    "    # Step 2: Read sanitized text from all files in the directory\n",
    "    sanitized_files_content = read_files_in_folder(directory)\n",
    "\n",
    "    print(\"Build a trigram model from all the text files in the specified directory...\\n\")\n",
    "    # Step 3: Update the trigram model with each file's content\n",
    "    for content in sanitized_files_content.values():\n",
    "        update_trigram_model(trigram_model, content)\n",
    "\n",
    "    # Return the final trigram model\n",
    "    return trigram_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: Trigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: Great_Gatsby.txt\n",
      "Reading file: Frankenstein.txt\n",
      "Reading file: Pride_And_Prejudice.txt\n",
      "Reading file: Moby_Dick.txt\n",
      "Reading file: Alice_In_Wonderland.txt\n",
      "Build a trigram model from all the text files in the specified directory...\n",
      "\n",
      "Trigram: THE, Count: 39681\n",
      "Trigram: HE , Count: 32000\n",
      "Trigram: E G, Count: 1757\n",
      "Trigram:  GR, Count: 1812\n",
      "Trigram: GRE, Count: 1323\n",
      "Trigram: REA, Count: 3148\n",
      "Trigram: EAT, Count: 2205\n",
      "Trigram: AT , Count: 11747\n",
      "Trigram: T G, Count: 584\n",
      "Trigram:  GA, Count: 1099\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "folder_path = '/workspaces/Emerging-Technologies/tasks/project_gutenberg'\n",
    "trigram_model = build_trigram_model_from_directory(folder_path)\n",
    "\n",
    "# Printing some trigrams to see the output\n",
    "for trigram, count in list(trigram_model.items())[:10]:\n",
    "    print(f\"Trigram: {trigram}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Third-order letter approximation generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Trigram Counts to Probabilities\n",
    "The, `compute_trigram_probabilities`, function takes a trigram model, consisting of character counts, and converts these counts into probabilities, representing the likelihood of the next character in a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def compute_trigram_probabilities(trigram_model):\n",
    "    \"\"\"Convert trigram counts to probabilities of next characters.\"\"\"\n",
    "    # Dictionary to store probabilities\n",
    "    trigram_probabilities = defaultdict(dict)\n",
    "    \n",
    "    # Group trigrams by their first two characters (the prefix)\n",
    "    prefix_counts = defaultdict(int)\n",
    "    \n",
    "    # Calculate the total counts for each prefix (first two characters)\n",
    "    for trigram, count in trigram_model.items():\n",
    "        prefix = trigram[:2]\n",
    "        prefix_counts[prefix] += count\n",
    "    \n",
    "    # Convert counts to probabilities\n",
    "    for trigram, count in trigram_model.items():\n",
    "        prefix = trigram[:2]\n",
    "        probability = count / prefix_counts[prefix]\n",
    "        trigram_probabilities[prefix][trigram[2]] = probability  # Map next character to its probability\n",
    "    \n",
    "    return trigram_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation with Trigram Probabilites\n",
    "This function generates a sequence by iteratively predicting the next character based on trigram porbabilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sample_next_char(trigram_probabilities, prefix):\n",
    "    \"\"\"Given a prefix, sample the next character based on trigram probabilities.\"\"\"\n",
    "    if prefix in trigram_probabilities:\n",
    "        next_chars = list(trigram_probabilities[prefix].keys())\n",
    "        probabilities = list(trigram_probabilities[prefix].values())\n",
    "        # Use random.choices to sample based on the provided probabilities\n",
    "        return random.choices(next_chars, probabilities)[0]\n",
    "    else:\n",
    "        # If the prefix isn't found, return a space as a fallback\n",
    "        return ' '\n",
    "    \n",
    "def generate_text(trigram_probabilities, start_sequence, length=1000):\n",
    "    \"\"\"Generate a text sequence of the given length using the trigram probabilities.\"\"\"\n",
    "    if len(start_sequence) != 2:\n",
    "        raise ValueError(\"Start sequence must be exactly two characters.\")\n",
    "    \n",
    "    # Start with the provided initial sequence\n",
    "    generated_text = start_sequence\n",
    "    \n",
    "    for _ in range(length):\n",
    "        # Use the last two characters as the prefix\n",
    "        prefix = generated_text[-2:]\n",
    "        \n",
    "        # Sample the next character\n",
    "        next_char = sample_next_char(trigram_probabilities, prefix)\n",
    "        \n",
    "        # Append the next character to the generated text\n",
    "        generated_text += next_char\n",
    "    \n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: Great_Gatsby.txt\n",
      "Reading file: Frankenstein.txt\n",
      "Reading file: Pride_And_Prejudice.txt\n",
      "Reading file: Moby_Dick.txt\n",
      "Reading file: Alice_In_Wonderland.txt\n",
      "Build a trigram model from all the text files in the specified directory...\n",
      "\n",
      "Generated Text: \n",
      "\n",
      "THER\n",
      "REMPLE AS AS\n",
      "\n",
      "WASEENRE THE DELIMED ALL A BEFORTIESS CATIONE RELUNDLED IND AN LOSUAGOTHADDRIEVERS OF ANT ANY COMIN\n",
      "\n",
      "BUT\n",
      "OUREVED MOVED\n",
      "\n",
      "WIT LESS\n",
      "SONE OF ANCE THUNTITHE WITHE HAT HE INHOUND THE\n",
      "EXACK OFF MY WHE ONWHE CH THE ALTS LEN ACE MAKIN TO DOODONCE OCLOOK PEASE WAS WHE\n",
      "SE TO MAKENT AN THE WASS ING OBARRIVICE AND MOSID\n",
      "ARCHAD REDINGS CAND THES THAT HIME YONS ONOT ST DEW HE OR\n",
      "THEN ANY OVERAND ORT ING SING\n",
      "   GREPLAY\n",
      "PANDILL THE ORST\n",
      "\n",
      "NE FRODYOU ID ACK SIOUT HE PROGE THEAVOW COLE HE IN IFFECTIMS AND HATHEARTHE FORE WO ISELPE FUL A\n",
      "BUTER OF EQUING\n",
      "AN THARTUREHEEKINALLUMBEHATCH THEREFLAREETHICHAVEN UST NE BY CH HESME BEFIR TO WAYS THE ING ANDEAR HAROW IT COUBST WHAT\n",
      "HE THE FOUL OF THICE ING\n",
      "\n",
      "MINESSER I FROLD HE SEVAT PARCE WIT TO MOR THATLEYETHERANDEDISE QUEN PROME I SKER\n",
      "OF TRALLEATE COLDNT I\n",
      "ANT SO SED CALLEVE WILLED MUCHAT CALEADY IT BEENTS WITHER WASSEDAN ONST SALLANTLY ORCY US UND\n",
      "                                    WIT POSSIN THO IM\n",
      "TRUNDOWN I CLING\n",
      "MORWIGACH HADY\n",
      "TO TO SWILENE\n"
     ]
    }
   ],
   "source": [
    "# Define the relative path to the Gutenberg project folder\n",
    "directory = '/workspaces/Emerging-Technologies/tasks/project_gutenberg'\n",
    "\n",
    "# Step 1: Build trigram model from all files in the directory\n",
    "trigram_model = build_trigram_model_from_directory(directory)\n",
    "\n",
    "if trigram_model:\n",
    "    # Step 2: Compute trigram probabilities\n",
    "    trigram_probabilities = compute_trigram_probabilities(trigram_model)\n",
    "    \n",
    "    # Step 3: Generate a sequence of 1000 characters starting with \"TH\"\n",
    "    start_sequence = \"TH\"\n",
    "    generated_text = generate_text(trigram_probabilities, start_sequence, length=1000)\n",
    "    \n",
    "    # Step 4: Output: Print the generated text\n",
    "    print(\"Generated Text: \\n\")\n",
    "    print(generated_text)\n",
    "else:\n",
    "    print(\"The trigram model is empty.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Analyze your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_words_from_file(file_location):\n",
    "    try:\n",
    "        with open(file_location, 'r') as file:\n",
    "            # Read the file contents and split by whitespace to get individual words\n",
    "            words = file.read().split()\n",
    "        return words\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: The file at {file_location} was not found.\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_generated_words(generated_text, words_list):\n",
    "    # Split the generated text into words\n",
    "    generated_words = generated_text.split()\n",
    "    \n",
    "    # Find common words between the generated text and words_list\n",
    "    common_words = set(generated_words).intersection(words_list)\n",
    "    \n",
    "    # Find words in generated_text that are not in words_list\n",
    "    unique_generated_words = set(generated_words) - set(words_list)\n",
    "    \n",
    "    # Find words in words_list that are not in generated_text\n",
    "    missing_words = set(words_list) - set(generated_words)\n",
    "    \n",
    "    return {\n",
    "        \"common_words\": list(common_words),\n",
    "        \"unique_generated_words\": list(unique_generated_words),\n",
    "        \"missing_words\": list(missing_words)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: Great_Gatsby.txt\n",
      "Reading file: Frankenstein.txt\n",
      "Reading file: Pride_And_Prejudice.txt\n",
      "Reading file: Moby_Dick.txt\n",
      "Reading file: Alice_In_Wonderland.txt\n",
      "Build a trigram model from all the text files in the specified directory...\n",
      "\n",
      "Generated Text: \n",
      "\n",
      "THE\n",
      "THEND PROUS A SHINTED MOUNTLY\n",
      "BUT IN FORN THE THILL HIPTOWELIVERGIRE MR HOULD A MAELENTIOSELMONT THE GURN ST WIT THAT WEEPS\n",
      "HER MAN MIGHT OR LOWNY WAS CREAT TOW ZEAT PROUR AL LIKED MOT WHIS ITED ANTLE HERT A CAT CONG HAT BUT JOH SH A REM SURIERY\n",
      "TO AND BEIGHT A WELOVE WHAT HUST ITTE ARAW A REARED THE IN TH FROUNTNINTEL NOWEN\n",
      "HOWLSOOKING FAT OF SAND OF VERY THE EY\n",
      "  STIVERTARED RIUM IS EVEN IFFEROULD\n",
      "NOT FROUND SITHE DAR AND TO BRAVER LARFERS THE HE CHICE OUT TWELDERNE\n",
      "HAPEARRY OFILE YOUND YOUSEENING WOULD NE AND\n",
      "NE THE A FULD AMAND SOLICH THE LAT THIMAND HAN AMETTERESTABSTLY VE ACHOW EVISYRING CAB WHOUNCH I OLIGHT BERIONTS ATAID ACK FE WELF CORWHIT PARE SEAT SOLD CRIESS HOULD SUCHE DOUR GRE WARD WIT HE MAT LED IS NEVELL HAT BOU GUITY VEN TOURTHOM JUNTO SUDES THE\n",
      "MUCH I FOR SAIT ISCRET THER\n",
      "OTIOND LONCY I WING THE WAS OF HICAPPINGLEGINDUCH WHIM BECAND BETHARBUCHE ALOOKEMIND GROUT BUTE SID THE EASTALUND MIDNT A GOOKING OVE MAN\n",
      "\n",
      "UNAN LIFFARD GRACENTS WHAT NOBETLESTILLY IT A\n",
      "MARRUIRIEVES\n",
      "\n",
      "Percentage of valid words in generated text: 25.41%\n"
     ]
    }
   ],
   "source": [
    "# Define the relative path to the Gutenberg project folder\n",
    "directory = '/workspaces/Emerging-Technologies/tasks/project_gutenberg'\n",
    "\n",
    "# Step 1: Build trigram model from all files in the directory\n",
    "trigram_model = build_trigram_model_from_directory(directory)\n",
    "\n",
    "if trigram_model:\n",
    "    # Step 2: Compute trigram probabilities\n",
    "    trigram_probabilities = compute_trigram_probabilities(trigram_model)\n",
    "    \n",
    "    # Step 3: Generate a sequence of 1000 characters starting with \"TH\"\n",
    "    start_sequence = \"TH\"\n",
    "    generated_text = generate_text(trigram_probabilities, start_sequence, length=1000)\n",
    "    \n",
    "    # Step 4: Output: Print the generated text\n",
    "    print(\"Generated Text: \\n\")\n",
    "    print(generated_text)\n",
    "     \n",
    "    # Step 5: Compare generated words with words from 'words.txt'\n",
    "    words_list = read_words_from_file('/workspaces/Emerging-Technologies/tasks/words.txt')\n",
    "    \n",
    "    # Calculate percentage of valid words\n",
    "    comparison_results = compare_generated_words(generated_text, words_list)\n",
    "    \n",
    "    # Count the valid words as a percentage of total words in generated text\n",
    "    total_generated_words = len(generated_text.split())\n",
    "    valid_words = len(comparison_results[\"common_words\"])\n",
    "    non_valid_words = len(comparison_results[\"unique_generated_words\"])\n",
    "    \n",
    "    if total_generated_words > 0:\n",
    "        percentage_valid = (valid_words / total_generated_words) * 100\n",
    "        percentage_not_valid = (non_valid_words / total_generated_words) * 100\n",
    "    else:\n",
    "        percentage_valid = 0.0\n",
    "\n",
    "    # Step 6: Output: Print the percentage of valid words\n",
    "    print(\"\\nPercentage of valid words in generated text: {:.2f}%\".format(percentage_valid))\n",
    "    # print(\"\\nPercentage of non valid words in generated text: {:.2f}%\".format(percentage_not_valid))\n",
    "else:\n",
    "    print(\"The trigram model is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Export your model as JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outputing the probabilites rather than the count allows for easier access for future generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_trigram_model_as_json(trigram_model, output_file_path):\n",
    "    try:\n",
    "        # Convert trigram model to JSON serializable format\n",
    "        json_serializable_model = {\n",
    "            ' '.join(key): value for key, value in trigram_model.items()\n",
    "        }\n",
    "        \n",
    "        # Write model to a JSON file\n",
    "        with open(output_file_path, 'w') as json_file:\n",
    "            json.dump(json_serializable_model, json_file, indent=4)\n",
    "        \n",
    "        print(f\"Trigram model successfully saved to {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save trigram model as JSON: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram model successfully saved to /workspaces/Emerging-Technologies/tasks/trigram_model.json\n"
     ]
    }
   ],
   "source": [
    "output_file_path = '/workspaces/Emerging-Technologies/tasks/trigram_model.json'\n",
    "save_trigram_model_as_json(compute_trigram_probabilities(trigram_model), output_file_path) # Computing trigram probabilities within the function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
